{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic business model for retail businesses is to stock the stores with merchandize to allow customers to make purchases at the locations. It is an important task for stores to know how much stock they need to acquire in the future. Failing in doing so, a store can lose money in one of two ways. Merchandize running out of stock too soon can lose potential revenue and having too much stock can result in failure to turn assets into revenue. Therefore, forecasting sales is crucial to the efficiency of store stocking. \n",
    "\n",
    "Conventionally, company can simply use sales data from previous months for stocking merchandize. For example, if one product has sold 5 units in the current month, then it may be likely that 5 more units will be sold next month if demand remains constant. However, the conventional method can be improved by using machine learning.\n",
    "\n",
    "The problem that the capstone project 2 is designed to solve is to forecast future sales of products in a collection of stores. The project is aimed to help companies to improve forecasting performance by using machine learning instead of using sales data of previous months as baseline model. Precise forecasting is particularly beneficial for stores that have products with high price tags and low profit margin. Electronic store, for example, has products with high price tags and low profit margin. Electronic store is vulnerable to over stocking because having too much merchandize in stock with high price can impact the company’s cash flow significantly.\n",
    "\n",
    "The dataset used in capstone project is obtained from the Predict Future Sales challenge on kaggle.com. The competition uses daily sales data provided by a Russian software firm, 1C Company, to predict total sales for every product and store in the coming month. The training set consists of time-series data of more than 20,000 unique item IDs (SKUs) in 50 stores. And the data span from January 2013 to October 2015. The test set is a collection of item-store labels for predicting the total sales of each item-store pairs in November 2015. There are also a set of files as supplemental information for shop location, item categories, and names of each items.\n",
    "\n",
    "Since the test set in the kaggle challenge does not provide the target variable, we will obtain our hold-out set from last month of the training data, which is October 2015. The data only shows sales record of 44 stores in October 2015, indicating that some stores are not in operation in the given month. By looking at the operation duration of each shop, we also found that one store opened during October 2015, which can be neglected due to insufficient data for making forecast for the store. Therefore, the number of stores in our forecast is reduced to 43. On the other hand, there are sales record for roughly 5000 unique item IDs in the month of September 2015 and about 5400 unique item IDs in October 2015, which are only fractions of the item IDs in the entire data set. \n",
    "\n",
    "There are different ways besides machine learning algorithms to make predictions for each product in stores. In this project, the optimal approach would be either bottom up and middle out approach. Bottom up approach predicts all of the time-series at the base level, which is directly calculating daily sale or monthly sale of each unique item ID in each store, and aggregate them to monthly sum. Middle out approach takes a middle level and calculate weights that represent the proportion of the total sales at the level would be given to each base level. Afterward, forecast at the middle level will be converted to the base level values. For example, we estimate the proportion of sales each shop would get for an item ID as weight, and divide the total monthly sale of that item ID by the weight to get the monthly sales of the item in the store. Middle out approach is ideal for data that contains hierarchical time series, which is the large number of unique items and stores in this case.\n",
    "\n",
    "The machine learning algorithms or forecasting procedures used in the project are random forest regressor, gradient boosting regressor, seasonal autoregressive integrated moving average (or SARIMA), and Prophet from Facebook. Both random forest regressor and gradient boosting regressor can be trained using the entire sales data to make predictions of total sales for each item-store pair, which is the bottom up approach. However, both SARIMA and Prophet can only be trained with a time series at a time. Thus, the latter are crucially limited by the amount of unique items in the hierarchal data set and are more suitable with middle out approach. \n",
    "\n",
    "ARIMA, which uses autoregressive and moving average of time series to forecast future values. And SARIMA is an extension of ARIMA method that supports seasonality in time-series. However, SARIMA has total of 8 hyperparameters that need to be configured to make proper predictions. It can take up to thousands of model fitting and predicting to perform grid search on hyperparameters to model a single SARIMA time-series. Because the data set has thousands of unique items, it can take millions of iterations even with middle out approach. \n",
    "\n",
    "Therefore, this project will only focus on forecasting the top 50 best selling items within the duration of the data set. To further increase the forecasting efficiency, a middle out approach of individual items will be used. Before making predictions, weights of each unique items in each store based on the prior month of prediction will be calculated. The ideology behind that is to use the proportion of an item’s total sale in a given month from each stores would be similar to how the next month would look like. On the other hand, it could be more noisy to use middle out approach on the store level, because the proportion of how each items are sold in a store may change drastically throughout each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
